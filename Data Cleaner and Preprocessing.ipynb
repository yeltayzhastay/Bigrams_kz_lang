{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "import re, codecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming functions, but don't use in python, because python works slowly. For this task you have to use GOlang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–ø—Ä–æ–≤–µ—Ä–∫–∞\n",
    "def comparison(word1, word2):\n",
    "    length = len(word2) if len(word1) > len(word2) else len(word1)\n",
    "    result = ''\n",
    "    for i in range(length):\n",
    "        if(word1[i] == word2[i]):\n",
    "            result = result + word1[i]\n",
    "        else:\n",
    "            break\n",
    "    return result\n",
    "#–ø—Ä–æ—Å—Ç–æ–π —Å—Ç–µ–º–º–∏–Ω–≥\n",
    "def stemming_kazakh(docin, doc):\n",
    "    alldocin = docin.split(' ')\n",
    "    docin = doc.split(' ')\n",
    "    result = []\n",
    "    for i in range(len(alldocin)):\n",
    "        for j in range(len(docin)):\n",
    "            s = comparison(alldocin[i], docin[j])\n",
    "            if(len(s) > 3):\n",
    "                docin[j] = s\n",
    "    \n",
    "    return \" \".join(str(x) for x in docin)\n",
    "#—Å—Ç–µ–º–º–∏–Ω–≥ –¥–ª—è –≤—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n",
    "def clean_all_datas(data_list):\n",
    "    merged = ' '.join(data_list[:100])\n",
    "    cleaned = []\n",
    "    iter = 1\n",
    "    length = len(data_list)\n",
    "    for i in data_list:\n",
    "        cleaned.append(stemming_kazakh(merged, i))\n",
    "        print(iter,'/',length)\n",
    "        iter += 1\n",
    "    return cleaned\n",
    "#–æ—á–∏—Å—Ç–∫–∞ –æ—Ç –Ω–µ–Ω—É–∂–Ω—ã–π(—à—É–º–Ω—ã—Ö) —Å–∏–º–≤–æ–ª–æ–≤\n",
    "def cleaning_data(code_data):\n",
    "    text = code_data.text.tolist()\n",
    "    label = code_data.label.tolist()\n",
    "    sentences = []\n",
    "    for line in range(len(text)):\n",
    "        pre = re.sub(r'http\\S+', '', str(text[line])).replace(r'<a href=\"', '')\n",
    "        stripped = re.sub('[^a-zA-Z, ^–ê-–Ø,–∞-—è,”ò,–Ü,“¢,“í,“Æ,“∞,“ö,”®,“∫,”ô,—ñ,…ô,“£,“ì,“Ø,“±,“õ,”©,“ª]', ' ', pre.replace('-', ''))\n",
    "        stripped = re.sub('_', '', stripped)\n",
    "        stripped = re.sub('\\s+', ' ', stripped)\n",
    "        sentences.append([str(stripped).lower(), int(label[line])])\n",
    "    return pd.DataFrame(sentences, columns = ['text', 'label'])\n",
    "#–∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ –∫–æ—Ç–æ—Ä—ã—Ö –±–æ–ª—å—à–µ 3 —Å–ª–æ–≤\n",
    "def more_three(df):\n",
    "    text = df.text.tolist()\n",
    "    label = df.label.tolist()\n",
    "    new_df = []\n",
    "    for i in range(len(text)):\n",
    "        if(len(text[i].split(' ')) > 5):\n",
    "            new_df.append([text[i], label[i]])\n",
    "        \n",
    "    return pd.DataFrame(new_df, columns = [\"text\", \"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading raw text and Writing clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>–õ–∏–≤–∞ –¢—É–≤–≤–∞—Ä –°–∏—Ä–∏—è –ê–ª–õ–∞–∂–∞—Ç—Ç–∞ # IslamState-“õ–∞ “õ–∞...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>—Ç–µ—Ä—Ä–æ—Ä–∏—Å—Ç—ñ–∫ –∏—Ç—Ç–µ—Ä –±“Ø–ª—ñ–∫—à—ñ–ª–µ—Ä–≥–µ –∞–π–Ω–∞–ª–∞–¥—ã! #Tur...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>”ò–ª-–•–∞–π—Ä–¥—ã“£ –ì–∞–∑–≤–∞—Ç—ã 13 –∞—Ä–Ω–∞–π—ã –∞–π–º–∞“õ. –û–ª–∞—Ä–¥–∞–Ω –∫–µ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>–°–∏—Ä–∏—è-–¥–∞“ì—ã # –†–µ—Å–µ–π | n '–±–∞—Å—ã–ø –∫—ñ—Ä—É' —Ç—É—Ä–∞–ª—ã –∞–ª–∞...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>–Ø–¥—Ä–æ–ª—ã“õ —Å–æ“ì—ã—Å —Å–æ“ì—ã—Å—ã –∫–µ–ª–µ –∂–∞—Ç—ã—Ä !!! &lt;a href=\"h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49523</th>\n",
       "      <td>–ñ–∞“õ—Å—ã ”©–º—ñ—Ä —Å“Ø—Ä—É–≥–µ —Ç—ã–π—ã–º —Å–∞–ª–∞ –∞–ª–º–∞–π—Å—ã–ΩüòÉ</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49524</th>\n",
       "      <td>91 –¥—ñ“£ –∫–æ–Ω—Ü–µ—Ä—Ç—ñ–Ω–µ –∂–∏–Ω–∞–ª“ì–∞–Ω –∏–≥–ª–∑–¥–∞—ÄüòÜ</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49525</th>\n",
       "      <td>–ü–∞–Ω–¥–∞–Ω—ã“£ “õ–∞–ª–∞–π –ø–∞–π–¥–∞ –±–æ–ª“ì–∞–Ω—ã–Ω –µ–Ω–¥—ñ —Ç“Ø—Å—ñ–Ω–¥—ñ–º......</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49526</th>\n",
       "      <td>–ú“Ø–±”ô—Ä”ô–∫ –±–æ–ª—Å—ã–Ω –ñ“±–º–∞“£—ã–∑‚òù, “ö–∞–±—ã–ª –±–æ–ª—Å—ã–Ω –¥“±“ì–∞“£—ã–∑üôè...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49527</th>\n",
       "      <td>–ö–µ–∑ –∫–µ–ª–≥–µ–Ω “ö–∞—Å“õ—ã—Ä—ã“£–¥—ã —à–∞“õ—ã—Ä –∞–π—Ä–∞–º—ã–ΩüòÑ</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49528 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      –õ–∏–≤–∞ –¢—É–≤–≤–∞—Ä –°–∏—Ä–∏—è –ê–ª–õ–∞–∂–∞—Ç—Ç–∞ # IslamState-“õ–∞ “õ–∞...      1\n",
       "1       —Ç–µ—Ä—Ä–æ—Ä–∏—Å—Ç—ñ–∫ –∏—Ç—Ç–µ—Ä –±“Ø–ª—ñ–∫—à—ñ–ª–µ—Ä–≥–µ –∞–π–Ω–∞–ª–∞–¥—ã! #Tur...      1\n",
       "2      ”ò–ª-–•–∞–π—Ä–¥—ã“£ –ì–∞–∑–≤–∞—Ç—ã 13 –∞—Ä–Ω–∞–π—ã –∞–π–º–∞“õ. –û–ª–∞—Ä–¥–∞–Ω –∫–µ...      1\n",
       "3      –°–∏—Ä–∏—è-–¥–∞“ì—ã # –†–µ—Å–µ–π | n '–±–∞—Å—ã–ø –∫—ñ—Ä—É' —Ç—É—Ä–∞–ª—ã –∞–ª–∞...      1\n",
       "4      –Ø–¥—Ä–æ–ª—ã“õ —Å–æ“ì—ã—Å —Å–æ“ì—ã—Å—ã –∫–µ–ª–µ –∂–∞—Ç—ã—Ä !!! <a href=\"h...      1\n",
       "...                                                  ...    ...\n",
       "49523             –ñ–∞“õ—Å—ã ”©–º—ñ—Ä —Å“Ø—Ä—É–≥–µ —Ç—ã–π—ã–º —Å–∞–ª–∞ –∞–ª–º–∞–π—Å—ã–ΩüòÉ      2\n",
       "49524                91 –¥—ñ“£ –∫–æ–Ω—Ü–µ—Ä—Ç—ñ–Ω–µ –∂–∏–Ω–∞–ª“ì–∞–Ω –∏–≥–ª–∑–¥–∞—ÄüòÜ      2\n",
       "49525  –ü–∞–Ω–¥–∞–Ω—ã“£ “õ–∞–ª–∞–π –ø–∞–π–¥–∞ –±–æ–ª“ì–∞–Ω—ã–Ω –µ–Ω–¥—ñ —Ç“Ø—Å—ñ–Ω–¥—ñ–º......      2\n",
       "49526  –ú“Ø–±”ô—Ä”ô–∫ –±–æ–ª—Å—ã–Ω –ñ“±–º–∞“£—ã–∑‚òù, “ö–∞–±—ã–ª –±–æ–ª—Å—ã–Ω –¥“±“ì–∞“£—ã–∑üôè...      2\n",
       "49527               –ö–µ–∑ –∫–µ–ª–≥–µ–Ω “ö–∞—Å“õ—ã—Ä—ã“£–¥—ã —à–∞“õ—ã—Ä –∞–π—Ä–∞–º—ã–ΩüòÑ      2\n",
       "\n",
       "[49528 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Corpus/big_corpus.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>–ª–∏–≤–∞ —Ç—É–≤–≤–∞—Ä —Å–∏—Ä–∏—è –∞–ª–ª–∞–∂–∞—Ç—Ç–∞ islamstate“õ–∞ “õ–∞—Ä—Å—ã...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>—Ç–µ—Ä—Ä–æ—Ä–∏—Å—Ç—ñ–∫ –∏—Ç—Ç–µ—Ä –±“Ø–ª—ñ–∫—à—ñ–ª–µ—Ä–≥–µ –∞–π–Ω–∞–ª–∞–¥—ã turke...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>”ô–ª—Ö–∞–π—Ä–¥—ã“£ –≥–∞–∑–≤–∞—Ç—ã –∞—Ä–Ω–∞–π—ã –∞–π–º–∞“õ –æ–ª–∞—Ä–¥–∞–Ω –∫–µ–π—ñ–Ω –æ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>—Å–∏—Ä–∏—è–¥–∞“ì—ã —Ä–µ—Å–µ–π n –±–∞—Å—ã–ø –∫—ñ—Ä—É —Ç—É—Ä–∞–ª—ã –∞–ª–∞“£–¥–∞–º–∞—É–¥...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>—è–¥—Ä–æ–ª—ã“õ —Å–æ“ì—ã—Å —Å–æ“ì—ã—Å—ã –∫–µ–ª–µ –∂–∞—Ç—ã—Ä</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45387</th>\n",
       "      <td>–∂–∞“õ—Å—ã ”©–º—ñ—Ä —Å“Ø—Ä—É–≥–µ —Ç—ã–π—ã–º —Å–∞–ª–∞ –∞–ª–º–∞–π—Å—ã–Ω</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45388</th>\n",
       "      <td>–¥—ñ“£ –∫–æ–Ω—Ü–µ—Ä—Ç—ñ–Ω–µ –∂–∏–Ω–∞–ª“ì–∞–Ω –∏–≥–ª–∑–¥–∞—Ä</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45389</th>\n",
       "      <td>–ø–∞–Ω–¥–∞–Ω—ã“£ “õ–∞–ª–∞–π –ø–∞–π–¥–∞ –±–æ–ª“ì–∞–Ω—ã–Ω –µ–Ω–¥—ñ —Ç“Ø—Å—ñ–Ω–¥—ñ–º</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45390</th>\n",
       "      <td>–º“Ø–±”ô—Ä”ô–∫ –±–æ–ª—Å—ã–Ω –∂“±–º–∞“£—ã–∑ , “õ–∞–±—ã–ª –±–æ–ª—Å—ã–Ω –¥“±“ì–∞“£—ã–∑ ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45391</th>\n",
       "      <td>–∫–µ–∑ –∫–µ–ª–≥–µ–Ω “õ–∞—Å“õ—ã—Ä—ã“£–¥—ã —à–∞“õ—ã—Ä –∞–π—Ä–∞–º—ã–Ω</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45392 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      –ª–∏–≤–∞ —Ç—É–≤–≤–∞—Ä —Å–∏—Ä–∏—è –∞–ª–ª–∞–∂–∞—Ç—Ç–∞ islamstate“õ–∞ “õ–∞—Ä—Å—ã...      1\n",
       "1       —Ç–µ—Ä—Ä–æ—Ä–∏—Å—Ç—ñ–∫ –∏—Ç—Ç–µ—Ä –±“Ø–ª—ñ–∫—à—ñ–ª–µ—Ä–≥–µ –∞–π–Ω–∞–ª–∞–¥—ã turke...      1\n",
       "2      ”ô–ª—Ö–∞–π—Ä–¥—ã“£ –≥–∞–∑–≤–∞—Ç—ã –∞—Ä–Ω–∞–π—ã –∞–π–º–∞“õ –æ–ª–∞—Ä–¥–∞–Ω –∫–µ–π—ñ–Ω –æ...      1\n",
       "3      —Å–∏—Ä–∏—è–¥–∞“ì—ã —Ä–µ—Å–µ–π n –±–∞—Å—ã–ø –∫—ñ—Ä—É —Ç—É—Ä–∞–ª—ã –∞–ª–∞“£–¥–∞–º–∞—É–¥...      1\n",
       "4                       —è–¥—Ä–æ–ª—ã“õ —Å–æ“ì—ã—Å —Å–æ“ì—ã—Å—ã –∫–µ–ª–µ –∂–∞—Ç—ã—Ä       1\n",
       "...                                                  ...    ...\n",
       "45387             –∂–∞“õ—Å—ã ”©–º—ñ—Ä —Å“Ø—Ä—É–≥–µ —Ç—ã–π—ã–º —Å–∞–ª–∞ –∞–ª–º–∞–π—Å—ã–Ω       2\n",
       "45388                   –¥—ñ“£ –∫–æ–Ω—Ü–µ—Ä—Ç—ñ–Ω–µ –∂–∏–Ω–∞–ª“ì–∞–Ω –∏–≥–ª–∑–¥–∞—Ä       2\n",
       "45389       –ø–∞–Ω–¥–∞–Ω—ã“£ “õ–∞–ª–∞–π –ø–∞–π–¥–∞ –±–æ–ª“ì–∞–Ω—ã–Ω –µ–Ω–¥—ñ —Ç“Ø—Å—ñ–Ω–¥—ñ–º       2\n",
       "45390  –º“Ø–±”ô—Ä”ô–∫ –±–æ–ª—Å—ã–Ω –∂“±–º–∞“£—ã–∑ , “õ–∞–±—ã–ª –±–æ–ª—Å—ã–Ω –¥“±“ì–∞“£—ã–∑ ...      2\n",
       "45391               –∫–µ–∑ –∫–µ–ª–≥–µ–Ω “õ–∞—Å“õ—ã—Ä—ã“£–¥—ã —à–∞“õ—ã—Ä –∞–π—Ä–∞–º—ã–Ω       2\n",
       "\n",
       "[45392 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = cleaning_data(df)\n",
    "df = more_three(df)\n",
    "df['text'] = df['text'].astype(str)\n",
    "df['label'] = pd.to_numeric(df['label'])\n",
    "df.to_csv('Corpus/big_corpus_cleaned.csv', index = False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36734\n",
      "1794\n",
      "6864\n"
     ]
    }
   ],
   "source": [
    "print(len(df.loc[df['label'] == 0].text))\n",
    "print(len(df.loc[df['label'] == 1].text))\n",
    "print(len(df.loc[df['label'] == 2].text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176539\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '—Å–∞“õ—Ç–∞–Ω–¥—ã—Ä—É—à—ã',\n",
       " '–µ–ª—à—ñ–ª—ñ–∫—Ç—ñ“£',\n",
       " '–∫–æ–ª–¥–∞–Ω—É',\n",
       " '–∫–ª—É–±—Ç–∞–Ω',\n",
       " '–¥“Ø–ø',\n",
       " '”©–∑–≥–µ—Ä—Ç–µ—Ç—ñ–Ω',\n",
       " '–æ“õ—ã—Ä–º–∞–Ω–Ω—ã“£',\n",
       " '–±i–ª—Éi',\n",
       " '–∂—ã–±—ã—Ä–ª–∞–ø']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docses = \" \".join(df.text.tolist())\n",
    "docses = re.sub('\\s+', ' ', docses)\n",
    "docses = list(set(docses.split(\" \")))\n",
    "pd.DataFrame(docses, columns = [\"unique\"]).to_csv(\"Corpus/big_unique_cleaned_words.csv\", index=False)\n",
    "print(len(docses))\n",
    "docses[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming_unique(doc1, doc2):\n",
    "    length1 = len(doc1)\n",
    "    for i in range(0, length1):\n",
    "        print(i, '/', length1)\n",
    "        for j in range(i, len(doc2)):\n",
    "            s = comparison(doc1[i], doc2[j])\n",
    "            if(len(s) > 5):\n",
    "                doc2[j] = s\n",
    "    \n",
    "    return list(set(doc2))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "unique_stem = stemming_unique(docses, docses)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(len(unique_stem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# There is have to run GOlang script in stemming_fast_process"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading after you've got Golang script's result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Corpus/big_corpus_stemmed.csv')\n",
    "df = cleaning_data(df)\n",
    "df['text'] = df['text'].astype(str)\n",
    "df['label'] = pd.to_numeric(df['label'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = more_three(df)\n",
    "df.to_csv(\"Corpus/corpus_stemmed_more3.csv\", index = False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
