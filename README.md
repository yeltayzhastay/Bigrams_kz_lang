# Bigrams_kz_lang
 
Данная работа состоить из двух задач
Цель первой задачи-определить Униграммы, биграммы и триграммы и визуализировать их.
А вторая задача - это классификация и кластеризация с использованием алгоритмов Наивного Байеса и Случайных Лесов
Работа первая
Для того чтобы работать с Ngram, вам нужна чистая очищенная и проходимая от стеммизации и лемматизации. На входе находится 5 файлов, 4 из которых являются экстремистскими текстами, а 1-неитральным. После считывания и обработки мы придаем ему его нормальную форму и делаем фрейм данных, первый столбец это текст, а вторым-двоичным значением обозначаем экзремистического текста. В конце таких обработок мы получаем 13168 строк и 2 столбца, а ниже приведена такая картина.
  
После этого мы удаляем ненужные элементы, html-теги, url-ссылки и внешние символы. Мы оставляем казахские, русские и латинские символы. В приведенном ниже коде вы можете увидеть несколько частей очищающих слов. Первая строка удаляет элементы html и url. Вторая строка оставляет только необходимые символы. Третья строка удаляет нижние пробелы. А в четвертой строке он заменяет несколько пробелов одним.
 
Результаты этой обработки следующие 
После очистки мы используем низкоуровневые языки программирования для выполнения stemmization. Для этой задачи я использовал высокоскоростной язык программирования Golang. Структурная схема текущего стемпинга
 
Функция отвечает за совпадение двух слов с самого начала до определенного количество символом. Существует также ограничение, если есть менее 4 совпадающих слов, то слово не меняется. В первом цикле документы объединяются, а во втором используется 13168 документов. Таким образом, результатом является этот фрейм данных
 
В языке программирование Golang этот процесс выполняется за 40 минут.
После вышеупомянутой обработки некоторые из наших документов стали пустыми и имеют мало словарного запаса. Это создает шум на тренировке. После устранения этой проблемы мы наконец получаем чистые данные.
 
А данные фрейма сокращаются на 11681 строку.
Униграммы, Биграммы, Триграммы
Для этого воспользуемся библиотекой sklearn. Он отлично подходит для векторизации наших данных. А именно, алгоритм CountVectorizer и TfidfVectorizer. Отображаем 20 лучших слов или фраз в Ngram.
Униграм:
   
Биграм:
   
 
Триграм:
   
 
Куадриграм:
   
 

Работа вторая
Мы используем различные библиотеки для классификации и кластеризации данных. Но самый главный из них sklearn. Потому что он идеально подходит для обучения и проверки тестовых данных, а также для различных операций машинного обучения. 
Использованные библиотеки:
	Pandas
	Numpy
	sklearn.model_selection
	sklearn.feature_extraction.text
	sklearn.metrics
	sklearn.naive_bayes
	sklearn.ensemble
	seaborn
	matplotlib
Перед тренировкой мы должны решить одну проблему. Неитральные данные 11681 документа, это 89% от общего числа. А экстремистских данных очень мало, их 1185 строк и это 11% от общего числа. Решение состоит в том, чтобы сбалансировать данные. Как это делается? Я сделал их 50 на 50. То есть 1185 строк для неитральных и экстремистских документов.
В результате мы имеем 2370 документов на обучение. 
После этой процедуры мы разделяем тренировочные и тестовые данные. Соотношение составляет 80% - train, 20% - test.
Для векторизации мы используем алгоритм TfidfVectorizer. Он отлично справляется с нашими данными.
Обучение
MultinomialNB - мультиномиальный наивный байесовский классификатор один из классификаторов для вычесление спам текста.
В результате обучения мы получаем такую картину
 
 
Это означает что обучение дает 97% точности.
GaussianNB
 
 
RandomForestClassifier - Основная идея заключается в использовании большого ансамбля решаюших деревьев, каждое из которых само по себе дает очень низкое качество классификации, но благодаря их большому количеству, результат получается неплохой.
 
 

Заключение
В заключение хочу сказать, что вышеперечисленные задачи были интересными и важными. Очистка и обработка данных повышает процент точности с 40-50 до 97 процентов. Так же как и балансировка данных дает 10-20 процентов, но положительный результат от балансировки дает равные шансы на определение нейтрального и эктремистического текста. Если бы не проделанная балансировка, почти 70-80 процентов экстремистических документов считались бы нейтральными. В конце концов, лучшим алгоритмом был Мультиномиальный наивный байесовский классификатор.
	MultinomialNB – 97%
	GaussianNB – 92%
	RandomForestClassifier – 96%
 

